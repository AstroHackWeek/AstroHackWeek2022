{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ad3bde",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Classifying JWST-HST galaxy mergers with CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9875",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2a9d0",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "\n",
    "**In this tutorial, you will see an example of building, compiling, and training a CNN on simulated astronomical data.**\n",
    "By the end of this tutorial you will have a working example of a simple Convolutional Neural Network (CNN) in `Keras`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324aa021",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "CNNs are a class of machine learning (ML) algorithms that can extract information from images.\n",
    "In this notebook, you will walk through the basic steps of applying a CNN to data:\n",
    "1. Load the data and visualize a sample of the data.\n",
    "2. Divide the data into training, validation, and testing sets.\n",
    "3. Build a CNN in `Keras`.\n",
    "4. Compile the CNN.\n",
    "5. Train the CNN to perform a classification task.\n",
    "6. Evaluate the results.\n",
    "\n",
    "CNNs can be applied to a wide range of image recognition tasks, including classification and regression.\n",
    "In this tutorial, we will build, compile, and train CNN to classify whether a galaxy has undergone a merger, using simulated Hubble Space Telescope images of galaxies.\n",
    "This work is based on the public data and code from <a href='https://ui.adsabs.harvard.edu/abs/2020A%26C....3200390C/abstract'>DeepMerge (Ciprijanovic et al. 2020)</a>. \n",
    "\n",
    "**NOTE:** *The DeepMerge team has [publicly-available code](https://github.com/deepskies/deepmerge-public) for demonstrating the architecture and optimal performace of the model, which we encourage you to check out! The goal of this notebook is to step through the model building and training process.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ee480",
   "metadata": {},
   "source": [
    "## Imports\n",
    "This notebook uses the following packages:\n",
    "- `numpy` to handle array functions\n",
    "- `astropy` for downloading and accessing FITS files\n",
    "- `matplotlib.pyplot` for plotting data\n",
    "- `keras` and `tensorflow` for building the CNN\n",
    "- `sklearn` for some utility functions\n",
    "\n",
    "If you do not have these packages installed, you can install them using [`pip`](https://pip.pypa.io/en/stable/) or [`conda`](https://docs.conda.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519891d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays\n",
    "import numpy as np\n",
    "\n",
    "# fits\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.visualization import simple_norm\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# sklearn (for machine learning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# from IPython import get_ipython\n",
    "# get_ipython().run_line_magic('matplotlib', 'notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3fcb1",
   "metadata": {},
   "source": [
    "### 1. Load the data and visualize a sample of the data\n",
    "\n",
    "Load the simulated galaxy observations (3-band images) and merger probabilities (output labels).\n",
    "\n",
    "In total, there are 15,426 simulated images, each in three filters (F814W from the Advanced Camera for Surveys and F160W from the Wide Field Camera 3 on the Hubble Space Telescope (HST), and F160W and F356W from Near Infrared Camera on the James Webb Space Telescope (JWST)), retrieved and augmented from synthetic observations of the Illustris cosmological simulation. The sample includes 8120 galaxy mergers and 7306 non-mergers. Two versions of the sample are available, with and without realistic observational and experimental noise (\"pristine\" and \"noisy\"). The sample construction and augmentation process for the HST images is described in detail in [Ciprijanovic et al. 2020](https://doi.org/10.1016/j.ascom.2020.100390), and is identical for the mock JWST images. \n",
    "\n",
    "These datasets are hosted at the Mikulski Archive for Space Telescopes as an the [DEEPMERGE](https://archive.stsci.edu/doi/resolve/resolve.html?doi=10.17909/t9-vqk6-pc80) high-level science product (HLSP). \n",
    "\n",
    "The CNN will be trained to distinguish between merging and non-merging galaxies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2527c",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944bd61",
   "metadata": {},
   "source": [
    "The simulated images are stored in FITS format. We refer you to the [Astropy Documentation](https://docs.astropy.org/en/stable/io/fits/index.html) for further information about this format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a55ee",
   "metadata": {},
   "source": [
    "For this example, we will download the \"pristine\" set of galaxy images, i.e., those without added observational noise. To select the \"noisy\" sample, change the version below. Alternatively, you can download data files from the [DEEPMERGE](https://stdatu.stsci.edu/hlsp/deepmerge) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01626c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'pristine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_url = 'https://archive.stsci.edu/hlsps/deepmerge/hlsp_deepmerge_hst-jwst_acs-wfc3-nircam_illustris-z2_f814w-f160w-f356w_v1_sim-'+version+'.fits'\n",
    "c(download_file(file_url, cache=True, show_progress=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e3a0dd",
   "metadata": {},
   "source": [
    "Explore the header of the file for information about its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73588651",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d36518",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu[1].header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc589f00",
   "metadata": {},
   "source": [
    "The file includes a primary header card with overall information, an image card with the simulated images, and a bintable with the merger labels for the images (1=merger, 0=non-merger)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaef9ba",
   "metadata": {},
   "source": [
    "#### Plot example images\n",
    "\n",
    "For a random selection of images, plot the images and their corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41380cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu[0].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed to get the same random set of images each time, or comment it out to get different ones!\n",
    "# np.random.seed(206265)\n",
    "\n",
    "# select 16 random image indices:\n",
    "example_ids = np.random.choice(hdu[1].data.shape[0], 16)\n",
    "# pull the F160W image (index=1) from the simulated dataset for these selections\n",
    "examples = [hdu[0].data[j, 1, :, :] for j in example_ids]\n",
    "\n",
    "# initialize your figure\n",
    "fig = plt.figure(figsize=(8, 8)) \n",
    "\n",
    "# loop through the randomly selected images and plot with labels\n",
    "for i, image in enumerate(examples):\n",
    "    ax = fig.add_subplot(4, 4, i+1)\n",
    "    norm = simple_norm(image, 'log', max_percent=99.75)\n",
    "\n",
    "    ax.imshow(image, aspect='equal', cmap='binary_r', norm=norm)\n",
    "    ax.set_title('Merger='+str(bool(hdu[1].data[example_ids[i]][0])))\n",
    "    \n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408afadf",
   "metadata": {},
   "source": [
    "## 2. Divide data into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ab807",
   "metadata": {},
   "source": [
    "To divide the data set into training, validation, and testing data we will use Scikit-Learn's [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function. \n",
    "\n",
    "We will denote the input images as `X` and their corresponding labels (i.e. the integer indicating whether or not they are a merger) as `y`, following the convention used by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cef745",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hdu[0].data\n",
    "y = hdu[1].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c578392b",
   "metadata": {},
   "source": [
    "Following the authors, we will split the data into 70:10:20 ratio of train:validate:test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eef99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as above, set the random seed to randomly split the images in a repeatable way. Feel free to try different values!\n",
    "random_state = 42\n",
    "\n",
    "X = np.asarray(X).astype('float32')\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "# First split off 30% of the data for validation+testing\n",
    "X_train, X_split, y_train, y_split = train_test_split(X, y, test_size=0.3, random_state=random_state, shuffle=True)\n",
    "\n",
    "# Then divide this subset into training and testing sets\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_split, y_split, test_size=0.666, random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a769e47",
   "metadata": {},
   "source": [
    "Next, reshape the image array as follows:  (number_of_images, image_width, image_length, 3).\n",
    "This is referred to as a \"channels last\" approach, where the final axis denotes the number of \"colors\" or \"channels\".\n",
    "The three-filter images have three channels, similar to RGB images like `jpg` and `png` image formats.\n",
    "CNN's will work with an arbitrary number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = np.shape(X_train)[2]\n",
    "\n",
    "X_train = X_train.reshape(-1, imsize, imsize, 3)\n",
    "X_valid = X_valid.reshape(-1, imsize, imsize, 3)\n",
    "X_test = X_test.reshape(-1, imsize, imsize, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1a5163",
   "metadata": {},
   "source": [
    "### 3. Build a CNN in `Keras`\n",
    "\n",
    "Here, we will build the model described in Section 3 of [Ciprijanovic et al. 2020](https://doi.org/10.1016/j.ascom.2020.100390).\n",
    "\n",
    "Further details about `Conv2D`, `MaxPooling2D`, `BatchNormalization`, `Dropout`, and Dense layers can be found in the [Keras Layers Documentation](https://keras.io/api/layers/). \n",
    "Further details about the sigmoid and softmax activation function can be found in the [Keras Activation Function Documentation](https://keras.io/api/layers/activations/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ca93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# generate the model architecture\n",
    "# Written for Keras 2\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Define architecture for model\n",
    "data_shape = np.shape(X)\n",
    "input_shape = (imsize, imsize, 3)\n",
    "\n",
    "x_in = Input(shape=input_shape)\n",
    "c0 = Convolution2D(8, (5, 5), activation='relu', strides=(1, 1), padding='same')(x_in)\n",
    "b0 = BatchNormalization()(c0)\n",
    "d0 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(b0)\n",
    "e0 = Dropout(0.5)(d0)\n",
    "\n",
    "c1 = Convolution2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same')(e0)\n",
    "b1 = BatchNormalization()(c1)\n",
    "d1 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(b1)\n",
    "e1 = Dropout(0.5)(d1)\n",
    "\n",
    "c2 = Convolution2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same')(e1)\n",
    "b2 = BatchNormalization()(c2)\n",
    "d2 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(b2)\n",
    "e2 = Dropout(0.5)(d2)\n",
    "\n",
    "f = Flatten()(e2)\n",
    "z0 = Dense(64, activation='softmax', kernel_regularizer=l2(0.0001))(f)\n",
    "z1 = Dense(32, activation='softmax', kernel_regularizer=l2(0.0001))(z0)\n",
    "y_out = Dense(1, activation='sigmoid')(z1)\n",
    "\n",
    "cnn = Model(inputs=x_in, outputs=y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454f58f",
   "metadata": {},
   "source": [
    "### 4. Compile the CNN\n",
    "\n",
    "Next, we compile the model.\n",
    "As in [Ciprijanovic et al. 2020](https://doi.org/10.1016/j.ascom.2020.100390), we select the Adam opmimizer and the binary cross entropy loss function (as this is a binary classification problem).\n",
    "\n",
    "You can learn more about [optimizers](https://keras.io/api/optimizers/) and more about [loss functions for regression tasks](https://keras.io/api/losses/) in the [Keras documentation](https://keras.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "optimizer = 'adam'\n",
    "fit_metrics = ['accuracy']\n",
    "loss = 'binary_crossentropy'\n",
    "cnn.compile(loss=loss, optimizer=optimizer, metrics=fit_metrics)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fca68b",
   "metadata": {},
   "source": [
    "### 5. Train the CNN to perform a classification task\n",
    "\n",
    "We will start with training for 20 epochs, but this almost certainly won't be long enough to get great results. We set the \"batch size\" of the network (i.e., the number of samples to be propagated through the network, see the keras documentation [here](https://keras.io/api/models/model_training_apis/)) to 128. Once you've run your model and evaluated the fit, you can come back here and run the next cell again for 100 epochs or longer.\n",
    "This step will likely take many minutes. The training step is typically the computational bottleneck for using CNNs.\n",
    "However, once a CNN is trained, it can effectively be \"packaged up\" for future use on the original or other machines.\n",
    "In other words, it doesn't have to be retrained every time one wants to use it!\n",
    "\n",
    "You can learn more about `model.fit` [here](https://keras.rstudio.com/reference/fit.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 20\n",
    "batch_size = 128\n",
    "shuffle = True\n",
    "\n",
    "# Train\n",
    "history = cnn.fit(X_train, y_train, \n",
    "                  batch_size=batch_size, \n",
    "                  epochs=nb_epoch, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  shuffle=shuffle,\n",
    "                  verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92fad3",
   "metadata": {},
   "source": [
    "### 6. Visualize CNN performance\n",
    "\n",
    "To visualize the performance of the CNN, we plot the evolution of the accuracy and loss as a function of training epochs, for the training set and for the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae194501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting from history\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = list(range(len(loss)))\n",
    "\n",
    "figsize = (6, 4)\n",
    "fig, axis1 = plt.subplots(figsize=figsize)\n",
    "plot1_lacc = axis1.plot(epochs, acc, 'navy', label='accuracy')\n",
    "plot1_val_lacc = axis1.plot(epochs, val_acc, 'deepskyblue', label=\"validation accuracy\")\n",
    "\n",
    "plot1_loss = axis1.plot(epochs, loss, 'red', label='loss')\n",
    "plot1_val_loss = axis1.plot(epochs, val_loss, 'lightsalmon', label=\"validation loss\")\n",
    "\n",
    "\n",
    "plots = plot1_loss + plot1_val_loss\n",
    "labs = [plot.get_label() for plot in plots]\n",
    "axis1.set_xlabel('Epoch')\n",
    "axis1.set_ylabel('Loss/Accuracy')\n",
    "plt.title(\"Loss/Accuracy History (Pristine Images)\")\n",
    "plt.tight_layout()\n",
    "axis1.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab9df0",
   "metadata": {},
   "source": [
    "Observe how the loss for the validation set is higher than for the training set (and conversely, the accuracy for the validation set is lower than for the training set), suggesting that this model is suffering from [overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit). Revisit [the original paper](https://ui.adsabs.harvard.edu/abs/2020A%26C....3200390C/abstract) and notice the strategies they employ to improve the validation accuracy. Observe [their Figure 2](https://www.sciencedirect.com/science/article/pii/S2213133720300445) for an example of what the results of a properly-trained network look like!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1309e",
   "metadata": {},
   "source": [
    "### 7. Predict mergers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9eed13",
   "metadata": {},
   "source": [
    "Apply the CNN to predict mergers in the \"test\" set, not used for training or validating the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc6fbe",
   "metadata": {},
   "source": [
    "Below, we use a confusion matrix to evaluate the model performance on the test data. See the documentation from [sklearn on confusion matrices](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52003db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cnn, input_data, input_labels):\n",
    "    \n",
    "    # Compute merger predictions for the test dataset\n",
    "    predictions = cnn.predict(input_data)\n",
    "\n",
    "    # Convert to binary classification \n",
    "    predictions = (predictions > 0.5).astype('int32') \n",
    "    \n",
    "    # Compute the confusion matrix by comparing the test labels (ds.test_labels) with the test predictions\n",
    "    cm = metrics.confusion_matrix(input_labels, predictions, labels=[0, 1])\n",
    "    cm = cm.astype('float')\n",
    "\n",
    "    # Normalize the confusion matrix results. \n",
    "    cm_norm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Plotting\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.matshow(cm_norm, cmap='binary_r')\n",
    "\n",
    "    plt.title('Confusion matrix', y=1.08)\n",
    "    \n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Merger', 'No Merger'])\n",
    "    \n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticklabels(['Merger', 'No Merger'])\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm_norm.max() / 2.\n",
    "    for i in range(cm_norm.shape[0]):\n",
    "        for j in range(cm_norm.shape[1]):\n",
    "            ax.text(j, i, format(cm_norm[i, j], fmt), \n",
    "                    ha=\"center\", va=\"center\", \n",
    "                    color=\"white\" if cm_norm[i, j] < thresh else \"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cnn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591d8de",
   "metadata": {},
   "source": [
    "## FAQ\n",
    "\n",
    "- **How do I interpret theses results?** The confusion matrix shows the model predicts a large fraction of false positive (roughly 25%) and false negative (roughly 36%) merger events. The published models from [Ciprijanovic et al. 2020](https://doi.org/10.1016/j.ascom.2020.100390) perform much better.  We note that in this notebook we are training for only a subset of the optimal number of epochs for space and time considerations, but you are welcome to agument these restricitons, and as always check out [the DeepMerge code](https://github.com/deepskies/deepmerge-public) for more information!\n",
    "\n",
    "\n",
    "- **Can I improve the model by changing it?** We only trained for 20 epochs, which is many fewer than the published model. Go back to Section 4 (\"Train the CNN to perform a classification task\") and increase the number of epochs to 100 (or more!) and train again. Does your model perform better? Your results may look better/worse/different from the published results due to the stochastic nature of training. \n",
    "\n",
    "\n",
    "- **Can I try a different model?  I think the results could be improved.** Yes!  You can try adding layers, swapping out the max pooling, changing the activation functions, swapping out the loss function, or trying a different optimizer or learning rate.  Experiment and see what model changes give the best results. You should be aware:  when you start training again, you pick up where your model left off.  If you want to \"reset\" your model to epoch 0 and random weights, you should run the cells to make and compile the model again.\n",
    "\n",
    "\n",
    "- **I want to test my model on my training data!** No. You will convince yourself that your results are much better than they actually are.  Always keep your training, validation, and testing sets completely separate!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee2cf0",
   "metadata": {},
   "source": [
    "### Extensions/Exercises\n",
    "\n",
    "- **Effect of noise?** Try re-training the network with \"noisy\" data (i.e., modify the `version` in Section 1 to \"noisy\" and download the associated data product). Do the results change? If so, how and why? What are the pros and cons of using noisy vs. pristine data to train a ML model? \n",
    "\n",
    "\n",
    "\n",
    "- **Effect of wavelength?** The [DEEPMERGE HLSP](https://archive.stsci.edu/doi/resolve/resolve.html?doi=10.17909/t9-vqk6-pc80) includes mock galaxy images in 2 filters only (only HST data). If you train the network with this data (hint: this will require downloading it from the website, or modifying the download cells to point to the correct URL; and also modifying the shapes of the training, validation and test data, as well as the network inputs), how do the results change? \n",
    "\n",
    "\n",
    "\n",
    "- **Early stopping?** The DeepMerge team employed \"early stopping\" to minimize overfitting. Try implementing it in the network here! The Keras library for [early stopping](https://keras.io/api/callbacks/early_stopping/) functions will be useful. For example, you can recompile the model, train for many more epochs, and include a `callback`, in `cnn.train` e.g.,\n",
    "\n",
    "    `callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)`\n",
    "    \n",
    "\n",
    "*Don't forget, [the DeepMerge team provides code](https://github.com/deepskies/deepmerge-public) for building their production-level model and verifying its results, please check them out for more extensions and ideas!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c2acc",
   "metadata": {},
   "source": [
    "## About this Notebook\n",
    "\n",
    "**Author:**  \n",
    "Claire Murray, Assistant Astronomer, cmurray1@stsci.edu  \n",
    "\n",
    "**Additional Contributors:**  \n",
    "Yotam Cohen, STScI Staff Scientist, ycohen@stsci.edu\n",
    "\n",
    "**Info:**  \n",
    "This notebook is based on the code repository for the paper <a href=\"https://doi.org/10.1016/j.ascom.2020.100390\">\"DeepMerge: Classifying High-redshift Merging Galaxies with Deep Neural Networks\"</a>, A. Ćiprijanović, G.F. Snyder, B. Nord, J.E.G. Peek, Astronomy & Computing, Volume 32, July 2020, and the notebook \"CNN_for_cluster_masses\" by Michelle Ntampaka, Assistant Astronomer, mntampaka@stsci.edu.\n",
    "\n",
    "**Updated On:** 2022-5-25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d60053a",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "If you use this data set, `astropy`, or `keras` for published research, please cite the\n",
    "authors. Follow these links for more information:\n",
    "\n",
    "* [Citing the data set](https://www.sciencedirect.com/science/article/pii/S2213133720300445#fn3)\n",
    "* [Citing `astropy`](https://www.astropy.org/acknowledging.html)\n",
    "* [Citing `keras`](https://keras.io/getting_started/faq/#how-should-i-cite-keras)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10703b3",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('zoobot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f17685d2e70c07ccb24ff33fa38795c5cafdc43f943119294282af8db3ae350a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
